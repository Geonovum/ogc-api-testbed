{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"OGC-API-Testbed Documentation","text":"<p>This documents the Geonovum OGC API Testbed Platform. Focus is on the Platform's design/setup, how it is provisioned (bootstrapped) and its continuous deployment/integration (CI/CD).</p> <p>Initially, the main goal of the Platform is to experiment with, and evaluate  various implementations of the OGC API Features (OAFeat) Standard. Given the generic nature of the Platform's web-services deployment architecture, additional services and OGC APIs may be added. The stable version of the Platform is provided as an Open Source GitHub Template, allowing any party to  derive and customize their own.</p> <p>Find a quick intro in the project README.</p> <p>The documentation is split up as follows:</p> <ul> <li>Setup describes the platform architecture and setup (admin manual)</li> <li>HOWTO has a number of tutorials on how to operate the system (user manual)</li> <li>Findings design choices, identified challenges and solutions</li> <li>Cases contains some experiments performed on the platform, and may be extended to capture future outcomes of the testbed</li> </ul>"},{"location":"#get-in-touch","title":"Get in Touch","text":""},{"location":"#services","title":"Services","text":"<p>To access and interact with the (OGC web-) services, go to  one of the two server instances:</p> <ul> <li>Stable (production) server at apitestbed.geonovum.nl</li> <li>Sandbox (experimental) server at apisandbox.geonovum.nl</li> </ul>"},{"location":"#links","title":"Links","text":"<ul> <li>Project GitHub Repo</li> <li>Geonovum - Geonovum home</li> <li>pygeoapi - <code>pygeoapi</code> project home</li> <li>ldproxy - <code>ldproxy</code> project home</li> <li>GeoServer - <code>GeoServer</code> home</li> <li>OGC API Features - OGC Home OAFeat</li> </ul>"},{"location":"cases/","title":"Cases","text":"<p>A number of specific experiments have been carried out.</p> <ul> <li>INSPIRE Case</li> <li>API Strategie Case</li> <li>Extending OGC API Features</li> <li>Skinning OGC API Features</li> </ul>"},{"location":"cases/INSPIRE/","title":"INSPIRE findings","text":"<p>The INSPIRE community has described an approach to provide INSPIRE Download services using OGC API Features. This document reviews this approach for various products used in the testbed.</p> <p>Similar to Atom the  Main principles of the approach indicate to set up a single api endpoint for this dataset. Both GeoServer and LDProxy offer capabilitiy to set up multiple endpoint within a single service, for pygeoapi we have to set up a new service.</p>"},{"location":"cases/INSPIRE/#requirements-class-inspire-pre-defined-data-set-download-oapif","title":"Requirements class \u201cINSPIRE-pre-defined-data-set-download-OAPIF\u201d","text":"MRCO Aspect pygeoapi GeoServer LDProxy Comment M Supports OpenApi 3.0 + + + GeoHealthCheck found issues in GeoServer and pygeoapi M /collections has metadata link for dataset + - ? pygeoapi is flexible for configuring any type of links C If HTML endoding, /collections has metadata link as html + - ? C For harmonised datasets, on collection level a  should be included to feature concept dictionary + - ? R For harmonised datasets, collectionid should match featuretype from IR + ? ? M /colections has link to license + - ? R License information in accordance with openapi + - - OpenAPI fields info/termsOfService or info/license are mentioned <p>M Mandatory, C Conditional, R Recommended, O Optional</p>"},{"location":"cases/INSPIRE/#requirements-class-inspire-multilinguality","title":"Requirements class INSPIRE-multilinguality","text":"<p>All aspects are conditional, in case the dataset is multilingual. pygeoapi landed a multiligual feature recently, other products seem to not have multilingual capabilities.</p> MRCO Aspect pygeoapi GeoServer LDProxy Comment C Support accept-language header + - - R Behaviour on no matching lang B B B Returns default language C Content language header + - - R Language support at all paths + - - M hreflang on enclosure links + - - <p>M Mandatory, C Conditional, R Recommended, O Optional</p>"},{"location":"cases/INSPIRE/#requirements-class-inspire-oapif-geojson","title":"Requirements class \u201cINSPIRE-OAPIF-GeoJSON\u201d","text":"MRCO Aspect pygeoapi GeoServer LDProxy Comment R document encoding rules to geojson ? ? ? no efforts yet <p>M Mandatory, C Conditional, R Recommended, O Optional</p>"},{"location":"cases/INSPIRE/#requirements-class-inspire-bulk-download","title":"Requirements class \u201cINSPIRE-bulk-download\u201d","text":"MRCO Aspect pygeoapi GeoServer LDProxy Comment M link to entire dataset + - - M link has type from inspire mediatypes + - - R link has length attribute + - - R link has title attribute + - - <p>M Mandatory, C Conditional, R Recommended, O Optional</p>"},{"location":"cases/INSPIRE/#requirements-class-inspire-crs","title":"Requirements class \u201cINSPIRE-CRS\u201d","text":"MRCO Aspect pygeoapi GeoServer LDProxy Comment R at least 1 supported CRS from list + + + <p>M Mandatory, C Conditional, R Recommended, O Optional</p>"},{"location":"cases/api_rules/","title":"API Strategie Findings","text":"<p>The knowledge Platform API's has published a normative document on REST-API design rules. This document explains how you can set up an OGC API service respecting these rules.</p> ID Aspect Comment API-01 Adhere to HTTP safety and idempotency semantics for operations API-02 Do not maintain session state on the server API-03 Only apply standard HTTP methods API-04 Define interfaces in Dutch unless there is an official English glossary available API-05 Use nouns to name resources Collections and items are user by name API-06 Use nested URIs for child resources Items are children of collections API-10 Model resource operations as a sub-resource or dedicated resource API-16 Use OpenAPI Specification for documentation API-17 Publish documentation in Dutch unless there is existing documentation in English API-18 Include a deprecation schedule when publishing API changes API-19 Schedule a fixed transition period for a new major API version API-20 Include the major version number in the URI API-48 Leave off trailing slashes from URIs API-51 Publish OAS document at a standard location in JSON-format API-53 Hide irrelevant implementation details API-54 Use plural nouns to name collection resources API-55 Publish a changelog for API changes between versions API-56 Adhere to the Semantic Versioning model when releasing API changes API-57 Return the full version number in a response header"},{"location":"cases/extending/","title":"Extending pygeoapi","text":"<p>An interesting use case around OGC API's is the ability to extend a base product with additional methods to facilitate more advanced data interaction. For example on a dataset with 'public announcements', citizens may want to interact with an announcement by sharing it with their friends, upvote or comment on it. </p> <p>Of all products in the testbed pygeoapi seems most appropriate to be extended to facilitate this use case. Unfortunately pygeoapi currently does not offer any extension points to add new methods. There is however the OGC API Processes endpoint which can be used for this purpose. Also I provide an example of an extension point in pygeoapi, to indicate how extensions are managed in pygeoapi.</p>"},{"location":"cases/extending/#ogc-api-processes","title":"OGC API processes","text":"<p>OGC API processes has a similar goal, to extend interacting with datasets by offering the capability to run processes on a dataset. The advantage is that users don't need to download the data, but can interact with the data at its origin. Processes are defined server side. Which processes are available is listed in the /processes endpoint.</p> <p>OGC API processes is more verbose then what people expect in modern api's. For example submitting 2 parameters to the hello-world process requires this input json object.</p> <pre><code>{\n  \"inputs\": [\n    {\n      \"id\": \"name\",\n      \"type\": \"text/plain\",\n      \"value\": \"World\"\n    },\n    {\n      \"id\": \"message\",\n      \"type\": \"text/plain\",\n      \"value\": \"An optional message.\"\n    }\n  ]\n}\n</code></pre> <p>Above data structure facilitates quite complex input parameters and is well described in the open api document. An important benefit is that this is a standadised client-server interaction. Both synchronous and asynchronous cases are supported by OGC API Processes.</p> <p>Read more on how processes can be defined in pygeoapi</p>"},{"location":"cases/extending/#extending-pygeoapi_1","title":"Extending pygeoapi","text":"<p>pygeoapi has been developed with the idea of running it standalone or as a library in for example GeoNode. The optimal way to extend pygeoapi is to create a dedicated project and add pygeoapi as a dependency to the project. Extending pygeoapi is currently most common in the provider section. Users are invited to write their own providr plugin which manages access to a dedicated backend.</p> <p>An example of this is https://github.com/Canadian-Geospatial-Platform/geocore-pygeoapi. The project is a provider plugin to access a dedicated spatial catalogue backend in order to provide an OGC API Records layer by pygeoapi. The project includes pygeoapi as a depenendy (via requirements.txt).</p>"},{"location":"cases/skinning/","title":"Skinning OGC API Features","text":"<p>HTML is a first class citizen in OGC API Common. This means that a typical OGC API can be accessed via a web browser, offering a human readable interface. This aspect brings in a usability aspect that providers previously didn't need to worry about. Aspects such as corporate identity, WCAG (accessibility), search engine optimisation or a cookie/privacy statement.</p> <p>For the experiment we want to understand how easy it is to update basic aspects on the html visualisation in various OGC API products.</p>"},{"location":"cases/skinning/#pygeoapi","title":"pygeoapi","text":"<p>pygeoapi uses jinja templates for html output. These templates are located at <code>~/pygeoapi/templates</code>. You can override these templates at their location. But you can also set a separate template override folder, where you can place (a part of the) updated templates. Updating the templates requires basic html skills, subsituted parameters are placed in curly braces:</p> <pre><code>  &lt;footer class=\"sticky\"&gt;Powered by &lt;a title=\"pygeoapi\" href=\"https://pygeoapi.io\"&gt;\n    &lt;img src=\"{{ config['server']['url'] }}/static/img/pygeoapi.png\" title=\"pygeoapi logo\" style=\"height:24px;vertical-align: middle;\"/&gt;\n    &lt;/a&gt; {{ version }}\n  &lt;/footer&gt; \n</code></pre>"},{"location":"cases/skinning/#pycsw","title":"pycsw","text":"<p>The implementation of OGC API Records in pycsw is derived from the pygeoapi implementation. The templates are located at <code>~/pycsw/ogc/api/templates</code>.</p>"},{"location":"cases/skinning/#qgis","title":"QGIS","text":"<p>QGIS uses similar jinja templates as pygeoapi, you can override the resources folder via the environment variable QGIS_SERVER_API_RESOURCES_DIRECTORY. The standard location of the templates is <code>~/qgis/resources/server/api/ogc/templates/wfs3</code>.</p>"},{"location":"cases/skinning/#geoserver","title":"GeoServer","text":"<p>GeoServer uses Freemarker templates to render content in html. These <code>.ftl</code> files are persisted within <code>.jar</code> files. A basic override approach could be to extract <code>gs-ogcapi-features.jar</code> to a folder, adjust the templates, and zip the package back to a <code>.jar</code> file and deploy it. GeoServer also provides a template override mechanism from the data folder. Read more at a dedicated blog on this topic.  Freemarker uses a similar substitution mechanism as jinja:</p> <pre><code>  &lt;li&gt;Mail: &lt;a href=\"mailto:${contact.contactEmail}\"&gt;${contact.contactEmail}&lt;/a&gt;&lt;/li&gt;\n</code></pre> <p>To highlight the impact of skinning, we have prepared a tailored skin for geoserver at https://apitestbed.geonovum.nl/geoserver/ogc/features. We've added a layout inspired on the GeoNovum website. For this, 2 layout template overrides have been added to <code>~/data/templates/ogc/features</code>.</p>"},{"location":"cases/skinning/#ldproxy","title":"LDProxy","text":"<p>The HTML encoding is implemented using Mustache templates. Custom templates are supported, they have to reside in the data directory under the relative path <code>templates/html/{templateName}.mustache</code>, where <code>{templateName}</code> equals the name of a default template (see source code on GitHub) (taken from ldproxy docs).</p>"},{"location":"cases/skinning/#geonetwork","title":"GeoNetwork","text":"<p>GeoNetwork offers an experimental OGC API Records implementation at https://github.com/geonetwork/geonetwork-microservices/tree/main/modules/services/ogc-api-records. This plugin can be installed on the latest v4 GeoNetwork. GeoNetwork uses xslt to provide a html interface. The xslt templates are located at https://github.com/geonetwork/geonetwork-microservices/tree/main/modules/services/ogc-api-records/src/main/resources/xslt/ogcapir. </p> <pre><code>  &lt;div class=\"w-2/3 pr-4\"&gt;\n    &lt;abstract&gt;\n      &lt;xsl:value-of select=\"$abstract\"/&gt;\n    &lt;/abstract&gt;\n  &lt;/div&gt;\n</code></pre>"},{"location":"credits/","title":"Credits","text":"<p>The OGC API Testbed Platform was initially developed in May-June 2021 by Geonovum.</p> <p>Developers were, alphabetically:</p> <ul> <li>Thijs Brentjens, also team-lead, point of contact</li> <li>Just van den Broecke</li> <li>Paul van Genuchten</li> </ul>"},{"location":"findings/","title":"Installation findings","text":"<p>This document lists some of the experiences during installation and creation of the software, for example:</p> <ul> <li>what is easy to do, what not?</li> <li>what is supported by which software?</li> <li>configuration setup</li> </ul>"},{"location":"findings/#docker","title":"Docker","text":"<p>Docker (and related Cloud-technologies like Kubernetes and Cloud Foundry) are replacing the traditional  installation and maintenance of web services, often dubbed as \"Box Hugging\". These Cloud-technologies are following the Pets vs Cattle paradigm.  Many pro's and con's are documented.  We list a number of them which came up during the project.</p> <p>Pro's</p> <ul> <li>For setups of pygeoapi and geoserver with OGR support (used in wfs and geopackage backend) the use of Docker is attractive, due to complexity of managing dedicated dependencies.</li> <li>Running the full platform locally doesn't require any effort. Traefik manages the change from https://domain to http://localhost transparently. But docker is the main driver of this capability.</li> </ul> <p>Con's</p> <ul> <li>In the field there is a growing awareness that docker also has limitations. Docker images do not receieve similar efforts to keep them updated as the traditional systems. The risk of non patched vulnarabilities is higher when running a docker infrastructue. </li> </ul>"},{"location":"findings/#data-management","title":"Data management","text":"<p>A typical use case will be that a geonovum employee arrives with some shapefiles to be published.  The Shapefile can be deployed as part of the deployment (via github). An alternative route is to import the data into postgres. The data can then be used in various applications. Importing a shapefile into postgres requires direct connection to postgres or use the PGAdmin dump import. GeoServer (via GeoCat Bridge) has an option to upload a shapefile and import it to Postgres. See HOWTO data on how to use both approaches.</p>"},{"location":"findings/#run-infra-locally","title":"Run infra locally","text":"<p>The current deployment can be run locally on Linux and Mac easily, which is helpful  to test a new development before creating the Pull Request.  However it may be the case that this does not easily work on Windows.  On the other hand, maybe this is not a scenario, because the Geonovum employee  might update the configuration in <code>GitHub</code>, and deploy it to the Sandbox environment,  and use that as a test prior to moving the configuration to the production system.</p>"},{"location":"findings/#use-of-attached-storage","title":"Use of attached storage","text":"<p>Using attached storage is common for larger files with a focus on read access. Can we use it to store grids (tiff) or tile cache to make it accessible for various services? Using attached storage as backend for geopackage or postgres is not optimal on attached storage because of many concurrent requests and file locking. Attached storage is usefull for bulk downloads (inspire stored query). Read access to a tilecache can be usefull, but seeding is problematic, due to the number of write requests.</p>"},{"location":"findings/#load-balancing","title":"Load balancing","text":"<p>Current setup does not have scaling (it is possible using traeffik, but currently not set up). It could be relevant to set up load balancing, at some point because it has its own type of challenges.</p> <p>Auto scaling as provided by for example Kubernetes, is not in scope for this experiment. Kubernetes generally requires a large hosting farm, such as azure, google.</p>"},{"location":"findings/#include-geoserver-in-the-experiment","title":"Include geoserver in the experiment?","text":"<p>We had some discussion if we should include GeoServer in the experiment. GeoServer is known to have challenges in cloud environments (memory usage, stability). But it is not explicitely known which challenges those are, and if their are ways to move around them. That's why it is usefull to include it. Also because the software has a high adoption at Dutch data providers.</p> <p>An aspect of GeoServer challenges in cloud is the complexity of its config files. The config files are designed around the web user interface which is commonly used to set them up, and heavily depends on relations identified by complex uuid strings. Running multiple geoservers along side requires to synchronise the config files over the instances. This gets extra challenging in case</p> <p>GeoServer has a jdbcconfig community module which allows to store the configuration in a database. But that plugin is not an official status yet (low TRL). Initiatives exist to define a geoserver cloud native strategy, based around an event bus.</p>"},{"location":"findings/#url-configuration","title":"URL configuration","text":"<p>Products tend to include a configuration parameter to indicate the outside url in which the service is made available. This url is for example used in a getcapabilities response to indicate the endpoint of the service. In CI/CD environments this parameter is challenging, because it may vary based on how you access the service (via internal or remote). There is actually no need to persist this in a parameter, because the value is also provided by the x-forwarded-for header of the request. Mind that the gateway software should be set up to add the x-forwarded-for header to the request. GeoServer facilitates for example this use case, in the settings you can activate a setting: 'use header for proxy url'.</p> <p>Traeffik caused additional challenges for the CSRF token check in geoserver. Seems you have to whitelist the proxy domain or disable csrf check at all (our choice). CSRF support has been added to recent geoserver versions, it offers an additional protection against script attacks.</p>"},{"location":"findings/#log-handling","title":"Log handling","text":"<p>To set up a proper mechanism to persist and visualise (error) logs is an important aspect of a successfull SDI implementation. Logs can be evaluated to find the cause of a problem, or more general find aspects to improve on the implementation. 3 types of logs can be identified:</p> <ul> <li>Error logs (generated by the application)</li> <li>Usage logs (typically at the gateway level)</li> <li>(un)availability (and hardware monitoring)</li> </ul> <p>Important aspects to evaluate is to prevent log files to grow to unexpected size and not get destructed at redeployment. Setting up proper log rotation is key. Another aspect to consider is that log files have a GDPR (AVG) aspect. Access logs typically persist ip adresses of endusers.</p>"},{"location":"findings/#error-logs","title":"Error logs","text":"<p>Within Docker it is a convention to report errors via stdout, so they are picked up by docker. LDProxy needs a dedicated configuration to set up logging to stdout.</p> <p>Tools like logstash are able to persist the logs from docker and visualise it in kibana. We have not implemented a central collection of error logs. Instead we delegate to portainer for viewing logs.</p>"},{"location":"findings/#usage-logs","title":"Usage logs","text":"<p>Traeffik needs to be set up to direct access-logs to a channel. A very basic option to persist and vizualise these logs is AWStats. More advanced tools are capable to cluster groups of requests, for example all requests within a certain bounding box or feature type.</p>"},{"location":"findings/#availability-logs","title":"Availability logs","text":"<p>Various generic products exist such as pingdom, checkmk, zabbix, nagios. Cloud platforms such as kubernetes have embedded systems. A dedicated product exists for the geospatial world, called GeoHealthCheck. It monitors the availability (and to a degree the complience) of gis layers. (see HOWTO ghc on how to use it)</p>"},{"location":"findings/#backup","title":"Backup","text":"<p>Backup (or synchronisation) should be set up for volatile data, such as databases and log files. These aspects are less relevant to this infrastructure, because we persist all configuration in GitHub and loss of the log files is not very critical. We therefore have not set up any backups or data synchronisation. </p>"},{"location":"howto/","title":"HOWTOs","text":"<p>The following sections of HOWTOs exist.</p>"},{"location":"howto/#howto-platform","title":"HOWTO Platform","text":"<p>The Platform section describes how to deploy and maintain  your own instance of the OGC API Testbed platform.</p> <ul> <li>HOWTO Platform - setting up a new platform</li> <li>HOWTO System Maintenance - maintaining the host system  </li> <li>HOWTO Error Analysis</li> </ul>"},{"location":"howto/#howto-services","title":"HOWTO Services","text":"<p>The deployment section describes how to deploy services, like OAFeat instances.</p> <ul> <li>HOWTO Deploy - create or update a service</li> <li>HOWTO Deploy pygeoapi</li> <li>HOWTO Deploy GeoServer</li> <li>HOWTO Deploy LDProxy</li> <li>HOWTO Deploy pycsw</li> <li>HOWTO Deploy qgis</li> <li>HOWTO Deploy GOAF</li> </ul>"},{"location":"howto/#howto-cases","title":"HOWTO Cases","text":"<p>The cases section describes how to manage certain use cases.</p> <ul> <li>HOWTO INSPIRE in pygeoapi</li> <li>HOWTO API Strategie</li> </ul>"},{"location":"howto/#howto-admin","title":"HOWTO Admin","text":"<p>The admin section describes various supporting tools for administration and monitoring.</p> <ul> <li>HOWTO GeoHealthCheck - monitoring OGC web-services</li> <li>HOWTO Database</li> <li>HOWTO Portainer - monitoring Docker Containers</li> </ul>"},{"location":"howto/howto_api_strategie/","title":"HOWTO set up a pygeoapi service following API Strategie","text":""},{"location":"howto/howto_database/","title":"HOWTO Database","text":"<p>The infrastructure has a central PostGreSQL database which can be used by various services.</p>"},{"location":"howto/howto_database/#managing-tables","title":"Managing tables","text":"<p>A Webbased database manager (pgAdmin) has been installed at https://apitestbed.geonovum.nl/pgadmin, which can be used to verify content in tables and administed tables and users. You can also create new tables and populate it using SQL queries (generated from a local database).</p>"},{"location":"howto/howto_database/#uploading-data-to-postgresql-from-qgis","title":"Uploading data to PostGreSQL from QGIS","text":"<p>The testbed database exposes its port to the web for conveniance purposes, this is not very common in production situations. This allows QGIS to directly connect to the database. And you can use the QGIS DB manager to upload data.</p> <ul> <li>Open the Data source manager to be able to add the testbed database to QGIS</li> </ul> key value service host apitestbed.geonovum.nl port 5432 database gis SSL allow user geopost pw xxxxx <ul> <li>Open DB Manager and select the testbed database</li> <li>Click the 'Import Layer/File' button and complete the wizard</li> </ul>"},{"location":"howto/howto_database/#connecting-geoserver-to-the-central-postgresql","title":"Connecting GeoServer to the central PostGreSQL","text":"<p>From GeoServer admin you can create a <code>store</code> which connects to the central database. After which you can set up feature collections originating from that store.</p> <ul> <li>On the stores page, create a <code>store</code>. Select a store of type PostGIS (not jndi).</li> <li>Fill in the connection details:</li> </ul> key value host postgis port 5432 database gis schema public user geopost pw xxxxx <ul> <li>From the layers screen, create a new layer.</li> <li>Select the PostGreSQL store</li> <li>Select the relevant table from the database.</li> <li>Fill in the Layer fields, at minimum calculate the bounds of the layer.</li> <li>Save and preview the layer</li> </ul>"},{"location":"howto/howto_database/#uploading-data-to-postgresql-from-qgis-bridge","title":"Uploading data to PostGreSQL from QGIS Bridge","text":"<p>As part of the data publication process of QGIS Bridge, you can configure the data to be stored on PostGreSQL. Two options exist (as configuration on a server connection):</p> <ul> <li>Bridge will send the data to GeoServer. And GeoServer will insert the data in PostGres.</li> <li>Bridge will connect directly to the remote PostGreSQL and insert the data</li> </ul>"},{"location":"howto/howto_deploy/","title":"Service Deployment","text":"<p>The API testbed environment uses a configuration mechanism stored in the GitHub repository.  Whenever GitHub detects a commit in the repository,  a deployment on the remote server of the changed service is triggered automatically.  Such an approach is known as Continuous Deployment or \"CD\".</p> <p>The API Testbed uses Ansible and GitHub Workflows to enable CD. Effectively, new or changed Docker Containers and their configuration are deployed on a remote server (VM/VPS) from within GitHub.</p> <p>While a deployment task is running, you can follow its progress  on GitHub.</p> <p>It is possible to directly commit your changes to GitHub, but a better practice is to  work from Pull Requests often called a PR.  Some discussion and an  approval process can happen around a Pull Request, before it is merged and deployed.</p> <p>For your case, decide if you want to update an existing service or create a new service.  All services in the platform are available as paths on a single domain.  Each service contains an orchestration of one or more Docker Containers,  which together provide the functionality of the service. Docker containers are based on of-the-shelf  product images from DockerHub, combined with a service-specific configuration.</p>"},{"location":"howto/howto_deploy/#update-a-service","title":"Update a service","text":"<p>Change the required files on an existing service folder.  Either directly on GitHub, but preferably by cloning the repository locally and issuing a PR.  Make the changes, commit, and push the changes.</p>"},{"location":"howto/howto_deploy/#create-a-new-service","title":"Create a new service","text":"<p>Firstly determine if you can instead update a service, for example with a new Collection, somewhat similar to a Layer.</p> <p>For a new service the best approach is to duplicate the entire folder of an existing service and change the required  parameters within that folder. NB be sure to also preserve the executable properties of the <code>.sh</code> (Shell) files!  Assumed is that the new service is using one of the existing components, thus services for GeoServer, pygeoapi, ldproxy etc.</p> <p>Creating a new service is basically the following multi-step process:</p>"},{"location":"howto/howto_deploy/#step-1-duplicate-folder","title":"Step 1 - Duplicate Folder","text":"<p>Duplicate the entire folder of an existing service and name it to the new service, say <code>xyz</code>. So it will reside in the folder <code>git/services/xyz/</code>.</p>"},{"location":"howto/howto_deploy/#step-2-adapt-variables","title":"Step 2 - Adapt Variables","text":"<p>In the best case only a single line in the file <code>git/services/xyz/env.sh</code> needs  to be adapted, i.e. the <code>SERVICE_NAME</code> variable. This will then automatically propagate the value for the subpath in the full service-URL plus other settings within the <code>docker-compose.yml</code> file. In the best case <code>docker-compose.yml</code> requires no changes.</p>"},{"location":"howto/howto_deploy/#step-3-adapt-service-config-and-data-files","title":"Step 3 - Adapt Service Config and Data File(s)","text":"<p>This step is specific to the service-component.  For example <code>pygeoapi</code> has a single <code>local.config.yml</code> file. In many cases the full service URL with the subpath needs to be adapted. Others, like GOAF, may need var-settings in the <code>docker-compose.yml</code> file. Usually you will add data files like GeoPackage-files on a <code>/data/</code> subfolder.</p>"},{"location":"howto/howto_deploy/#step-4-adapt-ansible-deploy-file","title":"Step 4 - Adapt Ansible Deploy File","text":"<p>Duplicate a service definition in  the Ansible Playbook file deploy.yml. This file is under <code>git/ansible/deploy.yml</code>.</p> <p>Use the service name for the service (folder) like:</p> <pre><code>    - name: \"xyz\"\n      shell: \"cd {{ services_home }}/xyz &amp;&amp; ./deploy.sh &amp;&amp; docker ps\"\n      tags: xyz\n</code></pre>"},{"location":"howto/howto_deploy/#step-5-create-a-github-action-file","title":"Step 5 - Create a GitHub Action File","text":"<p>This is a Action/Workflow File always to be placed under .github/workflows  GitHub should execute this file (for our repo)  when two conditions are met: </p> <p>1) a commit (direct or via a PR) to the <code>main</code> repository branch and  2) when the change is made to the new <code>services/xyz</code> folder (or a subfolder).</p> <p>Also here: easiest is to copy any existing service deploy file  like deploy.pygeoapi.yml and make a global change e.g. \"pygeoapi\" to \"xyz\".</p> <p>The file should look like:</p> <pre><code>name: xyz Deploy \u2699\ufe0f\n\n# Trigger only when services/xyz subdir changed\non:\n  push:\n    paths:\n      - 'services/xyz/**'\n\njobs:\n  main:\n    runs-on: ubuntu-24.04\n\n    steps:\n    - name: Checkout \u2705\n      uses: actions/checkout@v2\n\n    - name: Run playbook \u2699\n      uses: dawidd6/action-ansible-playbook@v2\n      with:\n        playbook: deploy.yml\n        directory: ./ansible\n        key: ${{secrets.ANSIBLE_SSH_PRIVATE_KEY}}\n        inventory: ${{secrets.ANSIBLE_INVENTORY_PROD}}\n        vault_password: ${{secrets.ANSIBLE_VAULT_PASSWORD}}\n        options: |\n          --tags xyz\n          --verbose\n\n</code></pre> <p>Basically this file will execute the above Ansible Playbook <code>deploy.yml</code> for the tag <code>xyz</code> whenever a change is committed/pushed to the <code>services/xyz/</code> folder.</p>"},{"location":"howto/howto_deploy/#testing-your-service","title":"Testing your service","text":"<p>You can either directly commit the service configuration in the sandbox and evaluate if it  behaves properly. Alternatively you can clone the full repository locally and run the environment locally  (installation of docker desktop is required) before committing. Always test your service in the sandbox  environment before duplicating it to the production environment.</p> <p>Navigate to the <code>git/services/</code> folder in the project and run <code>./start.sh</code></p>"},{"location":"howto/howto_errors/","title":"HOWTO Analyse Errors","text":"<p>Error analyses is a bit hidden but the platform has various options to analyse challenges.</p>"},{"location":"howto/howto_errors/#errors-during-deployment","title":"Errors during deployment","text":"<p>When you push a configuration change to github, a github action will trigger  to deploy the change to the platform. If such an action fails (the service is not available), the first step  is to open github actions and select the action related to your recent push. You can view the log of the action to look for a cause of the error.</p> <p>If you were not able to resolve the issue with above information, you can try to look for problems inside the  container, as described in the runtime error section.</p> <p>A next step is to run the full platform locally, as described in Run locally. And see if the problem can be resolved locally.</p> <p>A final step would be to roll back the change to restore the previous state of the platform.</p>"},{"location":"howto/howto_errors/#runtime-errors","title":"Runtime errors","text":"<p>Run time errors, such as incidental error pages, page not found/unresponsive, etc are best anaylised  via portainer. It is important to know the name of the container causing the error.  This name is assigned in the docker-compose file from which the project originates.</p> <p>Find the relevant container in portainer. From there you can view the logs of the conatainer, restart  it and even open a webbased command line client to it.</p>"},{"location":"howto/howto_errors/#unavailability","title":"Unavailability","text":"<p>Services being unavailable can have various causes. A first place to check is GeoHealthCheck to evaluate if other services also have problems and how long the problem already exists. Usually restarting the service via portainer will resolve the issue. Else there may be a deployment problem (in a worse case scenario it is caused by the deployment of another service).</p>"},{"location":"howto/howto_geoserver/","title":"HOWTO GeoServer","text":"<p>GeoServer is a commonly used application server providing webservices based on OGC standards. GeoServer provides a web interface to set up new services, including extended authorisation options. </p> <p>GeoServer uses a concept of workspaces to cluster a series of collections. Each workspace in GeoServer is set up as a separate OGC API Features endpoint, e.g. https://apitestbed.geonovum.nl/geoserver/{workspace}/ogc/features, although geoserver also has an endpoint with access to all collections from all workspaces.</p> <p>This document lists 2 approaches to set up OGC API Features services in GeoServer. Both approaches can not be combined in a single GeoServer instance. </p>"},{"location":"howto/howto_geoserver/#dynamical-setup","title":"Dynamical setup","text":"<p>GeoServer can be dynamically configured to add new services. 2 approaches are described:</p>"},{"location":"howto/howto_geoserver/#via-web-administrator","title":"Via Web Administrator","text":"<p>This HOWTO describes how you can upload data and set up a new layer on GeoServer via the Web Administrator.</p> <ul> <li>Most easy option to upload your data is to insert it into the PostGreSQL database using PGAdmin or QGIS DB manager.</li> <li>Log in to GeoServer</li> <li>From the Stores page, create a new store</li> <li>Select type PostGIS (not jndi), fill the connection details</li> </ul> key value host postgis port 5432 database gis schema public user geopost pw xxxxx <ul> <li>From the layers screen, create a new layer</li> <li>Select the PostGreSQL store and select the relevant table</li> <li>Fill in the various tabs (at least calculate the layer bounds)</li> <li>Test the layer via layer preview</li> </ul>"},{"location":"howto/howto_geoserver/#via-geocat-bridge","title":"Via GeoCat Bridge","text":"<p>This HOWTO describes how you can use QGIS to setup a new layer on GeoServer. For QGIS a plugin called GeoCat Bridge is available which  can publish a QGIS project as a workspace on GeoServer. The Bridge plugin is available via the plugins menu.</p> <p>We prepared a small video about the steps involved. </p>"},{"location":"howto/howto_geoserver/#scripted-setup","title":"Scripted setup","text":"<p>In a scripted setup the data folder of GeoServer is prepared locally and copied or mounted into the container as part of the deployment process. This setup is usefull when working with app-schema datasets ('complex GML'), which requires dedicated configuration which is not possible via the web administrator.</p> <p>A helpfull tool here is Hale, which has an option to export a prepared data folder for geoserver, including the pre configured app-schema configuration</p>"},{"location":"howto/howto_ghc/","title":"HOWTO GeoHealthCheck","text":"<p>GeoHealthCheck (GHC) provides a monitoring service which indicates availability and compliance to the  OGC API Features (OAFeat) standard.</p>"},{"location":"howto/howto_ghc/#ghc-model","title":"GHC Model","text":"<p>You may want to browse the GHC Presentation Slides to get an idea what GHC is about.</p> <p>The GHC conceptual model comprises the entities Resources, Probes and Checks.</p> <ul> <li>Resource : basically the (URL) access/endpoint of your service instance. Example: a WMS Endpoint</li> <li>Probe : action(s) performed on a Resource, for example a WMS GetMap request</li> <li>Checks: test results/responses of a Probe: Is the GetMap result an image?</li> </ul> <p>In the GHC UI you will manage these three entities.</p>"},{"location":"howto/howto_ghc/#add-monitoring-for-a-service","title":"Add Monitoring for a Service","text":"<ul> <li>navigate to the GHC page e.g. apitestbed.geonovum.nl/ghc/</li> <li>Login </li> <li>Click button upper right called Add+</li> <li>Select \"OGC API Features (OAFeat)\" Resource Type</li> <li>Add your full endpoint URL</li> </ul> <p>This brings you into the Resource Editor for your newly registered service endpoint (called a GHC Resource). By default, each new Resource gets a \"Capabilities Probe\" assigned which  checks the overall health of your endpoint (\"does it provide a valid Capabilities/OAS file?\") In the editor you can set various parameters and additional \"Probes\" and \"Checks\".</p> <p>Be sure to have at least the following two Probes active:</p> <ul> <li>OGC API Features (OAFeat) Capabilities - Validates OAFeat endpoint landing page    </li> <li>OGC API Features (OAFeat) Drilldown - Traverses all Collections in the endpoint validating if Features are returned </li> </ul> <p>The OGC API Features (OAFeat) OpenAPI Validator does a complete OAS3 JSON Schema validation on your OAS3 Endpoint JSON document. Most OAFeat implementations, except <code>pygeoapi</code> and <code>ldproxy</code> (as on June 30, 2021), fail this Probe.</p>"},{"location":"howto/howto_goaf/","title":"HOWTO GOAF","text":"<p>GOAF is a OAF implementaion in Go, maintained by PDOK, originally developed as Jivan.</p> <p>GOAF supports a PostGres or GeoPackage backend. Which file to serve the type of file are injected as environment variables.</p>"},{"location":"howto/howto_inspire/","title":"HOWTO INSPIRE &amp; pygeoapi","text":"<p>This HOWTO describes how to set up an INSPIRE service in pygeoapi for a Dutch INSPIRE dataset, Beschermde Gebieden - Cultuur Historie, which is exposed via a Atom download service.</p> <p>pygeoapi is configured using a config file. In this config file you have to add configuration for the inspire dataset. Note that one service provides access to a single dataset (having one or more feature types).</p> <p>Before starting verify if:</p> <ul> <li>Data is in a single language or multilingual</li> <li>Data is harmonised or as-is</li> </ul>"},{"location":"howto/howto_ldproxy/","title":"HOWTO ldproxy","text":"<p>LDProxy currently supports 2 backends, postgres and WFS. </p> <p>Before adding a layer, upload some data to the PostGreSQL database as described in the HOWTO Database</p> <p>Then open the LDProxy Manager and login as admin/*.</p> <p>Create a new service</p> <p>Read more at </p>"},{"location":"howto/howto_passwords/","title":"HOWTO passwords","text":"<p>Current setup does not have a single sign-on solution. All services have a dedicated password. All passwords are stored encrypted on Ansible Vault and injected into containers during deployment.</p>"},{"location":"howto/howto_passwords/#howto-extract-passwords","title":"HOWTO extract passwords","text":"<p>You can decrypt the passwords from the Ansible Vault using the master password, which is circulated separately.  You need Python and pip to decrypt:</p> <pre><code>pip install Ansible\n\nansible-vault decrypt git/ansible/vars/vars.yml\n</code></pre> <p>BE SURE TO NEVER CHECK-IN DECRYPTED FILES IN GITHUB!!</p> <p>Always be sure to encrypt after:</p> <pre><code>ansible-vault encrypt git/ansible/vars/vars.yml\n</code></pre>"},{"location":"howto/howto_passwords/#howto-add-or-change-a-password","title":"HOWTO add or change a password","text":"<p>TODO</p>"},{"location":"howto/howto_passwords/#howto-reference-a-ansible-password-from-yaml","title":"HOWTO reference a ansible password from YAML","text":"<p>TODO</p>"},{"location":"howto/howto_platform/","title":"HOWTO Platform","text":"<p>Describes how to setup your own instance of the OGC API Testbed platform. As a real-world example, the OGC API Sandbox (Playground) instance is presented below step-by-step.</p> <p>See also another example: a pygeoapi server developed by the EU JRC.</p>"},{"location":"howto/howto_platform/#1-ubuntu-server","title":"1. Ubuntu Server","text":"<p>Info:</p> <ul> <li>setup or acquire a Linux Ubuntu server, minimal Ubuntu 20.4 LTS</li> <li>can be a VM/VPS or bare metal server, even a local VirtualBox (with Vagrant) instance</li> <li>Sandbox specs: 4CPU, 16RAM, 100GB  but also strongly depends on the services one needs to run</li> <li>root access via SSH required</li> <li>DNS: create A-record <code>apisandbox.geonovum.nl</code> for IP address <code>109.237.219.249</code></li> <li>OPTIONAL: DNS: if you need docs (not for Sandbox) create CNAME and set in <code>git/docs/docs/CNAME</code></li> <li>copy your SSH public key to <code>/root/.ssh/authorized_keys</code>, e.g. <code>scp ~/.ssh/id_rsa.pub root@apisandbox.geonovum.nl:.ssh/authorized_keys</code></li> <li>test login with SSH key: <code>ssh root@apisandbox.geonovum.nl</code></li> <li>upgrade server to latest: <code>apt-get update &amp;&amp; apt-get -y upgrade</code></li> </ul>"},{"location":"howto/howto_platform/#2-generate-github-repo","title":"2. Generate GitHub Repo","text":"<p>Create a GitHub repository from the Template repo github.com/Geonovum/ogc-api-sandbox.</p> <p>Creating a repository from a template is similar to forking a repository, but there are important differences:</p> <ul> <li>A new fork includes the entire commit history of the parent repository, while a repository created from a template starts with a single commit.</li> <li>Commits to a fork don't appear in your contributions graph, while commits to a repository created from a template do appear in your contribution graph.</li> <li>A fork can be a temporary way to contribute code to an existing project, while creating a repository from a template starts a new project quickly.</li> </ul> <p>Steps (see also here:</p> <ul> <li>login on GitHub</li> <li>go to github.com/Geonovum/ogc-api-testbed</li> <li>above file list press green button \"Use this template\"</li> <li>follow the steps indicated, if you want to serve docs on a separate domain indicate \"Include all branches\"</li> </ul>"},{"location":"howto/howto_platform/#3-prepare-local-system","title":"3. Prepare Local System","text":"<p>On your local system:</p>"},{"location":"howto/howto_platform/#install-ansible","title":"Install Ansible:","text":"<ul> <li>have Python 3 (3.7 or better) installed</li> <li>OPTIONAL (but recommended) create a Python Virtualenv (for Ansible)  </li> <li>install Ansible with <code>pip install ansible</code> 2.9.* or higher</li> <li>test: <code>ansible --version</code> - shows ansible 2.9.19 ...</li> <li>test: <code>ansible-vault --version</code> shows ansible-vault 2.9.19 ...</li> </ul> <p>More on Ansible below.</p>"},{"location":"howto/howto_platform/#install-git-client","title":"Install <code>Git</code> client.","text":""},{"location":"howto/howto_platform/#4-clone-new-github-repo","title":"4. Clone New GitHub Repo","text":"<ul> <li><code>git clone https://github.com/Geonovum/ogc-api-sandbox.git</code></li> </ul> <p>We will call the root dir of the cloned git repo on your system just <code>git/</code> from here.</p>"},{"location":"howto/howto_platform/#5-setup-ansible","title":"5. Setup Ansible","text":"<p>Most of the configuration that is specific to your new server  is stored under <code>git/ansible/hosts</code> (Ansible inventories) and <code>git/ansible/vars</code> (variables and SSH keys). </p> <p>Most files are encrypted with <code>Ansible Vault</code>. You will need to  create your own (encrypted) version of these encrypted files.  For many files an example file is given. </p>"},{"location":"howto/howto_platform/#ansible-modules","title":"Ansible Modules","text":"<p>Called \"Roles\" these are third-party Ansible components that help with specific tasks. Install these as follows:</p> <pre><code>cd git/ansible\nansible-galaxy install --roles-path ./roles -r requirements.yml\n</code></pre>"},{"location":"howto/howto_platform/#ansible-hosts","title":"Ansible Hosts","text":"<p>The hostname is crucial to services functioning. Two steps:</p> <ul> <li>set content of <code>git/ansible/hosts/prod.yml</code> (Inventory) to</li> </ul> <pre><code>ogcapi:\n  hosts:\n    apisandbox:\n       ansible_port: 22\n       ansible_host: apisandbox.geonovum.nl\n       ansible_user: root\n\n</code></pre> <ul> <li>set content of <code>git/services/env.sh</code> to:</li> </ul> <pre><code>#!/bin/bash\n# Sets global env vars based on host-name\n# Needed for various host-dependent configs, especiallly Traefik SSL-certs.\n\n# Export and Defaults\n\n# Assume a local deployment\nexport DEPLOY_ENV=\"local\"\nexport TRAEFIK_SSL_ENDPOINT=\nexport TRAEFIK_SSL_DOMAIN=\"apisandbox.geonovum.nl\"\nexport TRAEFIK_SSL_CERT_RESOLVER=\nexport TRAEFIK_USE_TLS=\"false\"\nexport HOST_UID=$(id -u)\nexport HOST_GID=$(id -g)\nexport HOST_UID_GID=\"${HOST_UID}:${HOST_GID}\"\n\n# Set host-dependent vars\ncase \"${HOSTNAME}\" in\n    \"apisandbox.geonovum.nl\")\n        DEPLOY_ENV=\"prod\"\n        ;;\n    \"apisandbox\")\n        DEPLOY_ENV=\"prod\"\n        ;;\n    *)\n        echo \"Default Local Host ${HOSTNAME}\"\nesac\n\nif [[ ${DEPLOY_ENV} = \"prod\" ]]\nthen\n    source /etc/environment\n    TRAEFIK_SSL_ENDPOINT=\"https\"\n    TRAEFIK_SSL_CERT_RESOLVER=\"le\"\n    TRAEFIK_USE_TLS=\"true\"\nfi\n\n</code></pre> <p>So <code>DEPLOY_ENV=prod</code> here is to discern with a deployment on <code>localhost</code> (<code>DEPLOY_ENV=local</code>, where .e.g. no https/SSL is used).</p>"},{"location":"howto/howto_platform/#create-ssh-keys","title":"Create SSH Keys","text":"<p>These are used to invoke actions on the server both from GitHub Actions (via GitHub Sercrets)  and from your local Ansible setup. Plus a set of authorized_keys for the admin SSH user.</p> <ul> <li>cd <code>git/ansible/vars</code></li> <li>create new SSH keypair (no password): <code>ssh-keygen -t rsa -q -N \"\" -f gh-key.rsa</code></li> </ul>"},{"location":"howto/howto_platform/#create-authorized_keys","title":"Create authorized_keys","text":"<p>Create new <code>git/ansible/vars/authorized_keys</code> with your public key and for others you want to give access to the admin SSH account, plus <code>gh-key.rsa.pub</code> .</p> <pre><code>cat gh-key.rsa.pub &gt; authorized_keys\ncat ~/.ssh/id.rsa.pub &gt;&gt; authorized_keys\ncat id.rsa.pub.of.joe &gt;&gt; authorized_keys   # etc\n\n</code></pre>"},{"location":"howto/howto_platform/#adapt-varsyml","title":"Adapt vars.yml","text":"<p>Create new <code>git/ansible/vars/vars.yml</code> from example <code>vars.example.yml</code> in that dir.</p> <p>The first part of <code>vars.yml</code> contains generix, less-secret, values.  Use variables where possible. Format is Python-Jinja2 template-like:</p> <pre><code>my_ssh_pubkey_file: ~/.ssh/id_rsa.pub\nmy_email: my@email.nl\nmy_admin_user: the_admin_username\nmy_admin_home: \"/home/{{ my_admin_user }}\"\nmy_git_home: \"{{ my_admin_home }}/git\"\nmy_github_repo: https://github.com/Geonovum/ogc-api-sandbox.git\nvar_dir: /var/ogcapi\nlogs_dir: \"{{ var_dir }}/log\"\nservices_home: \"{{ my_git_home }}/services\"\nplatform_home: \"{{ my_git_home }}/platform\"\npip_install_packages:\n  - name: docker\ntimezone: Europe/Amsterdam\nufw_open_ports: ['22', '80', '443', '5432']\n</code></pre> <p>The second part deals with more secret values, like usernames and passwords for services. For most services indicated below with comment after <code>#</code>. <code>GHC_</code> denotes GeoHealthCheck (GHC) vars. If you don't use GHC you can skip those.</p> <pre><code>etc_environment:\n  PG_DB: the_db  # PostGIS service\n  PG_USER: the_user  # PostGIS service\n  PG_PASSWORD: the_pw  # PostGIS service\n  PGADMIN_EMAIL: the_user@the_user.nl # PGadmin service\n  PGADMIN_PASSWORD: the_pw  # PGadmin service\n  GHC_SQLALCHEMY_DATABASE_URI: postgresql://the_user:the_pw@the_db:5432/the_db  # PGadmin service\n  GHC_ADMIN_USER_NAME: the_user\n  GHC_ADMIN_USER_PASSWORD: the_pw\n  GHC_ADMIN_USER_EMAIL: the_user@the_user.nl\n  GHC_NOTIFICATIONS_EMAIL: the_user@the_user.com\n  GHC_SMTP_EMAIL: the_user@the_user.com\n  GHC_SMTP_SERVER: smtp.gmail.com\n  GHC_SMTP_PORT: 587\n  GHC_SMTP_TLS: True\n  GHC_SMTP_SSL: False\n  GHC_SMTP_USERNAME: the_user@the_user.com\n  GHC_SMTP_PASSWORD: the_pw\n\n</code></pre>"},{"location":"howto/howto_platform/#create-ansible-vault-password","title":"Create Ansible Vault Password","text":"<ul> <li>global replace <code>~/.ssh/ansible-vault/ogc-api-testbed.txt</code> with <code>~/.ssh/ansible-vault/ogc-api-sandbox.txt</code> in <code>git/ansible/README.md</code></li> <li>create strong password  </li> <li>store in <code>~/.ssh/ansible-vault/ogc-api-sandbox.txt</code> for convenience</li> </ul>"},{"location":"howto/howto_platform/#set-github-secrets","title":"Set GitHub Secrets","text":"<p>Three secrets need to be set:</p> <p>Go to GH repo Settings|Secrets and create these three secrets</p> <ul> <li>ANSIBLE_INVENTORY_PROD - with value from <code>git/ansible/hosts/prod.yml</code></li> <li>ANSIBLE_SSH_PRIVATE_KEY - with value from <code>git/ansible/vars/gh-key.rsa</code></li> <li>ANSIBLE_VAULT_PASSWORD - value from <code>~/.ssh/ansible-vault/ogc-api-sandbox.txt</code> </li> </ul>"},{"location":"howto/howto_platform/#encrypt-ansible-files","title":"Encrypt Ansible Files","text":"<p>VERY IMPORTANT. UNENCRYPTED FILES SHOULD NEVER BE CHECKED IN!!!</p> <p>Using <code>ansible-vault</code> with password encrypt these:</p> <pre><code>ansible-vault encrypt --vault-password-file ~/.ssh/ansible-vault/ogc-api-sandbox.txt  vars.yml\nansible-vault encrypt --vault-password-file ~/.ssh/ansible-vault/ogc-api-sandbox.txt  gh-key.rsa\nansible-vault encrypt --vault-password-file ~/.ssh/ansible-vault/ogc-api-sandbox.txt  gh-key.rsa.pub \nansible-vault encrypt --vault-password-file ~/.ssh/ansible-vault/ogc-api-sandbox.txt  authorized_keys \n\n</code></pre>"},{"location":"howto/howto_platform/#globally-replace-apitestbedgeonovumnl","title":"Globally Replace apitestbed.geonovum.nl","text":"<p>Under <code>git/services</code> replace all occurrences of <code>apitestbed.geonovum.nl</code> with <code>apisandbox.geonovum.nl</code></p>"},{"location":"howto/howto_platform/#disable-github-workflows","title":"Disable GitHub Workflows","text":"<p>We do not want that workflows take effect immediately.  So disable them temporary by renaming the dir.</p> <pre><code>git mv workflows workflows.not\ngit add .\ngit commit -m \"disable workflows\"\ngit push\n\n</code></pre>"},{"location":"howto/howto_platform/#6-prune-repo-tree-for-unneeded-services","title":"6 Prune Repo Tree for Unneeded Services","text":"<p>At this step you may want to delete services you don't need:</p> <ul> <li><code>rm -rf git/docs</code> . Documentation is already maintained and available via https://apitestdocs.geonovum.nl/ </li> <li>for each service you want to delete, delete these 3 resources, e.g. for service <code>xyz</code><ul> <li><code>rm -rf git/services/xyz</code></li> <li><code>rm  git/.github/workflows/deploy.xyz.yml</code></li> <li>in <code>git/ansible/deploy.yml</code> delete the three Ansible <code>task</code> lines with <code>xyz</code> name and tag.</li> </ul> </li> </ul>"},{"location":"howto/howto_platform/#7-bootstrapprovision-server","title":"7 Bootstrap/provision Server","text":"<p>Moment of truth! Bootstrap (provision the server) in single playbook.</p> <ul> <li><code>ansible-playbook -v --vault-password-file ~/.ssh/ansible-vault/ogc-api-sandbox.txt bootstrap.yml -i hosts/prod.yml</code></li> </ul> <p>If all goes well, this output should be shown at end:</p> <pre><code>PLAY RECAP ***********************************************************************************************************\napisandbox                 : ok=58   changed=22   unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   \n\n</code></pre> <p>Observe output for errors (better is to save output in file via <code>.. &gt; bootstrap.log 2&gt;&amp;1</code>).</p> <p>In cases of errors and after fixes, simply rerun the above Playbook.</p> <p>Site should be running at: https://apisandbox.geonovum.nl Check with portainer https://apisandbox.geonovum.nl/portainer/.</p>"},{"location":"howto/howto_platform/#8-resolve-issues","title":"8 Resolve Issues","text":"<p>These are typical issues found and resolved:</p> <ul> <li><code>/home/oadmin/git</code> is owned by root, change to <code>oadmin</code> </li> <li>delete (or change) CNAME <code>git/docs/docs</code></li> <li>permissions in services/qgis/data , make datadir writeable for all: <code>chmod 777 services/qgis/data</code></li> </ul>"},{"location":"howto/howto_platform/#9-enable-github-workflows","title":"9. Enable GitHub Workflows","text":"<p>Enable by renaming:</p> <pre><code>git mv workflows.not workflows \ngit add .\ngit commit -m \"enable workflows\"\ngit push\n\n</code></pre>"},{"location":"howto/howto_portainer/","title":"HOWTO Portainer","text":"<p>Portainer is a webbased tool which allows to manage running docker containers. You can view logs of a container, evaluate hardware usage, restart it or even ssh into it.</p> <p>Portainer is available at https://apitestbed.geonovum.nl/portainer. Credentials of portainer are circulated as part of the infrastructure credentials.</p>"},{"location":"howto/howto_pycsw/","title":"HOWTO pycsw","text":"<p>pycsw operates on a postgres or sqlite backend. The database is configured in a configuration file, together with other common settings.</p>"},{"location":"howto/howto_pycsw/#loading-data","title":"Loading data","text":"<p>pycsw has a tool to load data from a folder of files. Alternatively CSW transactions (from for example GeoCat Bridge) can be used to insert data. But transactions need to be explicitely activated and require an authentication mechanism.</p>"},{"location":"howto/howto_pygeoapi/","title":"HOWTO pygeoapi","text":"<p>The pygeoapi config is the place to start when configuring a new service. The file starts with some general server configuration and then presents a list of collections. Each collection has a data store configuration referencing one of the available data backends. A common data provider is the OGR/GDAL provider which gives access to a multitude of file formats.</p> <p>In a minimal approach you can update the current config file and add a new layer to it. </p> <p>Alternatively you can create a new instance by duplicating the main pygeoapi service folder under a new name and update the main ansible orchestration to add the new service. Also you have to create a new file in https://github.com/Geonovum/ogc-api-testbed/tree/main/.github/workflows, having the new name. This tells github to (re)deploy the service when changes are detected. Note that INSPIRE mandates that each dataset is exposed via a unique service endpoint and pygeoapi can only provide a single service endpoint. Duplicating the deployment is then a usual approach.</p>"},{"location":"howto/howto_pygeoapi/#example-of-a-pygeoapi-collection","title":"Example of a pygeoapi collection","text":"<pre><code>lakes:                                                      # name of the collection, e.g. /collection/lakes/items\n        type: collection \n        title:                                              # title, keywords and description support multilingual\n            en: Large Lakes\n            nl: Grote meren                               \n        description: lakes of the world, public domain\n        keywords:\n            - lakes\n        crs:                                                # CRS-es supported by backend\n            - CRS84\n        links:                                              # list of links to more info, for example metadata\n            - type: text/html\n              rel: canonical\n              title: information\n              href: http://www.naturalearthdata.com/\n              hreflang: en-US\n        extents:                                            # spatial and temporal extent of the layer\n            spatial:\n                bbox: [-180,-90,180,90]\n                crs: http://www.opengis.net/def/crs/OGC/1.3/CRS84\n            temporal:\n                begin: 2011-11-11\n                end: null  # or empty\n        providers:                                          # list of backends\n            - type: feature                                 # service type (e.g. features, maps, styles, records, coverages)\n              name: GeoJSON                                 # type of provider (see docs for available types)\n              data: tests/data/ne_110m_lakes.geojson        # link to a file (or other provider specific configuration)\n              id_field: id                                  # field which contains the identifier\n              title_field: name                             # field which contains the title of the element (can be multilingual)\n</code></pre>"},{"location":"howto/howto_qgis/","title":"HOWTO QGIS server","text":"<p>QGIS server is configured through QGIS Desktop. The project file generated with QGIS is then uploaded to the server (along with any data to serve).</p> <ul> <li>Start a new project in QGIS, or update an existing.</li> <li>Add the relevant layers to the project. For file based data, place the files in (or under) the folder where the project is stored, else QGIS may generate unresolvable paths in the project file.</li> <li>If you want to use a database layer, upload any data to the remote PostGreSQL. Connect your local QGIS to the remote database and add the PostGreSQL tables as layers to the project.</li> <li>Go to Project Properties, open the QGIS Server tab, fill in relevant fields. Make sure to check the \"publish\" checkbox in the WFS section, else no collections will be available.</li> <li>Save the project as .qgs file (not .qgz) and push it to Github with all related files.</li> <li>The project should be called project.qgs. Alternatively you can set an environment variable </li> </ul> <pre><code>QGIS_PROJECT_FILE:/etc/qgisserver/my-new-project.qgs\n</code></pre> <ul> <li>Test your service via https://apitestbed.geonovum.nl/qgis/wfs3</li> </ul>"},{"location":"howto/howto_skinning/","title":"HOWTO adjust the looks of OGC API Features","text":"<p>Tutorials on how to change the look and feel of OGC API features.</p>"},{"location":"howto/howto_skinning/#geoserver","title":"GeoServer","text":"<p>This toturial updates the main headr and footer of GeoServer OGC API Features, other templates can be overridden in a similar way.</p> <ul> <li>In the data directory which is mounted into geoserver add files templates/ogc/features/common-header.ftl and templates/ogc/features/common-footer.ftl</li> <li>Adjust the files to your needs and push the changes to github</li> <li>Tip, you can preview your changes without updating the platform by adjusting the html and css directly in the web page with the browser developer panel (F12)</li> </ul>"},{"location":"howto/howto_system/","title":"HOWTO System Maintenance","text":"<p>Once a platform instance, as in HOWTO Platform, has  been installed the host system needs to be maintained. In our case the (remote) host  system runs Ubuntu. A Debian/Ubuntu system is composed of software \"Packages\". These can become outdated and need to be updated. Also packages may contain security fixes.  In some cases all the Docker Containers may need a restart (Service Management).</p> <p>Below is described how the above is organized and how these tasks are enabled for a maintainer.  *NB all this applies to the host/VM system-OS, not the OS-es that run within the Docker Containers!!</p> <p><code>~/.ssh/ansible-vault/ogc-api-sandbox.txt</code> is the file containing your Ansible Vault password.</p>"},{"location":"howto/howto_system/#security-updates","title":"Security Updates","text":"<p>Automatic updates of (Ubuntu) security fixes/patches is already done automatically. During the Ansible Bootstrap phase, the Ansible Module justb4.ubuntu-base will enable  automatic security updates.</p> <p>Details: the specific Ansible Task can be found here.</p>"},{"location":"howto/howto_system/#service-management","title":"Service Management","text":"<p>All Docker containers can be started/stopped by a Ubuntu <code>systemd</code> service called <code>ogcapi</code>. </p> <p>The following Ansible tasks are available:</p> <pre><code>ansible-playbook -v --vault-password-file ~/.ssh/ansible-vault/ogc-api-sandbox.txt service.yml -i hosts/prod.yml --tags status\n\nansible-playbook -v --vault-password-file ~/.ssh/ansible-vault/ogc-api-sandbox.txt service.yml -i hosts/prod.yml --tags stop\n\nansible-playbook -v --vault-password-file ~/.ssh/ansible-vault/ogc-api-sandbox.txt service.yml -i hosts/prod.yml --tags start\n\n</code></pre>"},{"location":"howto/howto_system/#system-management","title":"System Management","text":"<p>The Ubuntu \"APT\" packages can be maintained remotely with Ansible. The host system can even be rebooted remotely.  The systemd service <code>ogcapi</code> (see Service Management) and thus all Docker Containers will be started  automatically.</p> <p>The following Ansible tasks are available:</p> <pre><code># Update outdated Packages\nansible-playbook -v --vault-password-file ~/.ssh/ansible-vault/ogc-api-sandbox.txt system.yml -i hosts/prod.yml --tags update_packages\n\n# Reboot - all services should come back up\nansible-playbook -v --vault-password-file ~/.ssh/ansible-vault/ogc-api-sandbox.txt system.yml -i hosts/prod.yml --tags reboot\n\n</code></pre>"},{"location":"setup/","title":"Setup","text":"<p>This section describes the setup/installation details of the platform.</p>"},{"location":"setup/#platform-setup","title":"Platform setup","text":"<p>This section introduces the setup of the platform and  components used in the platform infrastructure.</p> <ul> <li>Platform setup </li> </ul>"},{"location":"setup/#operational-services","title":"Operational Services","text":"<p>A number of services is deployed on the platform:</p> <ul> <li>pygeoapi</li> <li>pycsw</li> <li>GeoServer</li> <li>ldproxy</li> <li>QGIS Server</li> <li>GOAF</li> <li>postgis / pgadmin</li> </ul>"},{"location":"setup/#admin-tools","title":"Admin tools","text":"<p>Some admin tools are made available to monitor the platform. </p> <ul> <li>portainer</li> <li>GeoHealthCheck</li> </ul>"},{"location":"setup/geoserver/","title":"Setup GeoServer","text":"<p>A docker hub image is provided by oscarfonts is extended with OGC API plugin. The binaries of the plugin, as well as the data folder are mounted into the container. The <code>Oscar Fonts</code> image runs as a tomcat user, which by itself is a good practice from security prespective, but files are created on the data folder by a user unknown to the docker host, which causes problems at redeployment. We have overridden this behaviour and run as root user.</p> <p>The data folder is created by deploying geoserver locally, setting up the required services and commit the changes to github. You can either embed a data file inside the data folder, alternatively you can upload data to the PostGreSQL database and configure a layer on data from the database.</p> <p>The OGC API is available from the geoserver homepage at /ogc/features, or on the workspace endpoint /{workspace}/agc/features.</p>"},{"location":"setup/geoserver/#ogc-api-community-module","title":"OGC API Community module","text":"<p>The GeoServer community has been involved in the OGC sprints while the standards were shaped to its current form. The implementation of OGC API currently has the form of a community plugin, which can be installed on recent versions of GeoServer.</p>"},{"location":"setup/geoserver/#scripted-configuration-vs-dynamic-configuration","title":"Scripted configuration vs dynamic configuration","text":"<p>GeoServer has an extended web user interface as well as a rest api to configure the publication of datasets. These configurations are persisted as xml files in the config folder. Alternatively you can use a scripted approach to configure the server, the xml files in the conig folder are deployed as part of the deployment. Both approaches can however not easily be combined. It means you have to decide for a server if you set it up scripted or dynamically. The scripted approach is mostly used in advanced setups such as App Schema INSPIRE.</p> <p>Most challenging is a sequential update number which is updated with every dynamic update of the configuration via the api.</p> <p>The configuration with xml files is also a challenge when scaling out and load balancing GeoServer. When these files are updated by one instance, the other instances need to be synchronised. Some community plugins are available, such as jdbc-config, which enables the storage of configuration in a central database. </p>"},{"location":"setup/geoserver/#geoserver-behind-a-gateway-traefik","title":"GeoServer behind a gateway (traefik)","text":"<p>Running GeoServer behind a gateway, which exposes geoserver at an alternative domain, requires a proxy url to be configured on GeoServer. You need to manage this in an xml file, because the admin interface (which offers an option to configure this also) doesn't work correctly if the proxy url is not correctly set up.</p> <p>Recent versions of GeoServer have added a CSRF protection against script attacks. This CSRF leads to unexpected results when running GeoServer via a gateway. The gateway domain needs to be whitelisted or CSRF vealidation deactivated. Read more at https://docs.geoserver.org/stable/en/user/security/webadmin/csrf.html</p>"},{"location":"setup/geoserver/#geoserver-and-docker","title":"GeoServer and docker","text":"<p>The installation of GeoServer requires to add the OGC API plugin (check a matching version number). It is quite common that GeoServer is extended with plugins. We used the docker image provided by oscarfonts, which has a nice mechanism to place plugins (and data folder) on a mounted volume.</p> <p>In order to configure a new resource on GeoServer we added the required configuration files to the geonovum github repository. GeoServer also has a web interface and rest api to configure resources, but note that any resource added manually may be overwritten from github with the new deployment of the software.</p> <p>An alternative for manual setup us the GeoCat bridge tool, which is a typical tool to configure new resources on GeoServer from within the QGIS or ArcMAP Desktop application.</p>"},{"location":"setup/geoserver/#template-overrides","title":"Template overrides","text":"<p>We experimented with template overrides to add the geonovum corporate identity to the OGC API endpoints. We found some interesting behaviour, which we reported to the GeoServer community. To override common-header.ftl for /collections, you need to add the override in /data/templates/ogc/features. To override it for /items you need to place it in data/workspaces.</p>"},{"location":"setup/geoserver/#geopackage-support","title":"GeoPackage support","text":"<p>GeoPackage is often mentioned as a replacement for (appschema) GML to share larger datasets efficiently. GeoServer has support for GeoPackage as output format after installing a dedicated community plugin. The plugin also requires the wps plugin to be installed. Both plugins are installed and verified that these can be used as export format for OGC API Features.</p>"},{"location":"setup/geoserver/#issues","title":"Issues","text":"<p>Some issues found during deployment </p> <ul> <li>Issue #22 - Permission Issue for mounted dirs: the GeoServer Container permanently changes the ownership of mounted dirs</li> <li>Issue #21 - OGC API Plugin: running on subpath with https does not render linked resources correctly</li> <li>GEOS-10125 - GeoServer currently does not add the (meta)data linksto the links section in /collections endpoint</li> <li>GEOS-10126 - GeoServer uses deprecated mediatype application/x-gpkg.</li> </ul>"},{"location":"setup/ghc/","title":"GeoHealthCheck","text":"<p>GeoHealthCheck (GHC) is an  availability and Quality-of-Service (QoS) monitoring solution  dedicated to OGC (web-) services. GHC supports both the  standard protocols like WMS, WFS, WMTS, CSW etc, APIs in general and  the recent OAFeat OGC standard. To learn more, best is to  follow a GHC presentation as HTML slides or video.</p>"},{"location":"setup/ghc/#oafeat-support","title":"OAFeat Support","text":"<p>GHC supports the OGC OAFeat standard with two basic checks (called \"Probes\"):</p> <ul> <li>OAFeat endpoint traversal, check if all required resources/links are available</li> <li>full OAS schema validation</li> </ul>"},{"location":"setup/ghc/#deployment","title":"Deployment","text":"<p>GHC is part of the Admin Stack in the testbed.</p> <p>GeoHealthCheck has Docker Images available at  DockerHub  and uses a standard PostgreSQL/PostGIS database for persistence.</p> <p>GHC runs with three Docker containers:</p> <ul> <li>GHC Web Application (<code>ghc_web</code>)</li> <li>GHC Runner (runs the actual checks) (<code>ghc_runner</code>)</li> <li>GHC Postgres database stores check config and results (<code>ghc_db</code>)</li> </ul>"},{"location":"setup/ghc/#configuration","title":"Configuration","text":"<p>GHC needs quite some variables (around 31, though many defaults apply).  These are all configured once in ghc.env.  Many variables represent credentials like email and  database configuration. These are bundled as <code>etc_environment</code>  in and forwarded from the encrypted Ansible file <code>vars.yml</code>.</p> <pre><code>    - name: \"admin\"\n      shell: \"cd {{ services_home }}/admin &amp;&amp; ./deploy.sh &amp;&amp; docker ps\"\n      tags: admin\n\n</code></pre>"},{"location":"setup/ghc/#links","title":"Links","text":"<ul> <li>docker-compose.yml - the Docker Compose file</li> </ul>"},{"location":"setup/goaf/","title":"Setup GOAF","text":"<p>GOAF is a OAF implementaion in Go, maintained by PDOK, originally developed as Jivan.</p> <p>GOAF image used from https://hub.docker.com/r/pdok/wfs-3.0, this is an older version, but PDOK has not updated yet. Alternative could be to build the image from sources.</p> <p>GOAF supports a PostGres or GeoPackage backend. Which file to serve the type of file are injected as environment variables.</p> <p>We have added the default BRT image provided by PDOK as example.</p>"},{"location":"setup/ldproxy/","title":"LDProxy installation experiences/hints","text":"<p>ldproxy started out as a prototype in the GeoNovum Geo4Web testbed in 2016.  Over the years LDProxy has followed the developments around OGC API  and is currently the most complete implementation of the latest developments in OGC API.</p>"},{"location":"setup/ldproxy/#installation","title":"Installation","text":"<p>A docker hub image is provided by Interactive Instruments. </p> <p>We are using the latest image provided by Interactive Instruments,  which is a bit behind from the latest version on their docker repository,  but that repository is not available publicly yet. We found (and reported)  some issues with the latest public release, which should be solved in the main branch.</p> <p>We are mounting the config folder to a local volume, the configuration in the  folder is taken from github. The configuration includes a config file in which logging  to stdout has been set up.</p> <p>For this moment we only expose a feature service with a RCE WFS as backend.  We intend to also add a service with a postgres backend.</p> <p>The data folder is created by deploying ldproxy locally, setting up the required services and commit the changes to github. You can upload data to the PostGreSQL database and configure a layer on data from the database.</p> <p>The OGC API's are available via /ldproxy/services.</p> <p>Configure logging to stdout</p> <p>Challenges when exposing ldprocy on a subpath</p>"},{"location":"setup/ldproxy/#issues","title":"Issues","text":"<ul> <li>running <code>ldproxy</code> on a subpath does not provide proper URLs to internal e.g. CSS resources</li> <li>Issue error on accessing collection for RCE WFS</li> </ul> <pre><code>Client error, HTTP status 406, Request path : MessageBodyWriter not found for media type=image/avif, \ntype=class java.util.ArrayList, genericType=class java.util.ArrayList.\n\n</code></pre>"},{"location":"setup/platform/","title":"Platform setup","text":"<p>The project repository contains contains components to bootstrap, configure (\"provision\") and maintain a remote deployment of an OGC API web-service stack using modern \"DevOps\" tooling.</p> <p></p> <p>See also a presentation of the platform on OpenGeodag 2021.</p>"},{"location":"setup/platform/#design-principles","title":"Design Principles","text":"<p>The main design principles are:</p> <ul> <li>starting point is an empty VPS/VM with Ubuntu and root (key) access</li> <li>any action on the server/VM host is performed from a client host</li> <li>i.e. no direct access/login to/on the server/VM is required, only for problem solving</li> <li>remote actions can be performed manually or triggered by GitHub Workflows</li> <li>all credentials (passwords, SSH-keys, etc) are secured </li> <li>two operational stack instances 1) production, \"Stable\" and 2) playground, \"Sandbox\"</li> </ul>"},{"location":"setup/platform/#components","title":"Components","text":"<p>The components used to realize this design are:</p> <ul> <li>Docker \"...OS-level virtualization to deliver software in packages called containers...\" (Wikipedia)</li> <li>Docker Compose \"...a tool for defining and running multi-container Docker applications...\"</li> <li>Ansible \"...an open-source software provisioning tool\" (Wikipedia)</li> <li>GitHub Actions/Workflows \"...Automate, customize, and execute software development workflows in a GitHub repository...\"</li> <li>Traefik a frontend proxy/load-balancer and SSL (HTTPS) endpoint.</li> </ul> <p>The Docker-components are used to run the operational stack, i.e. the OGC API web-services and supporting services like for monitoring.  Ansible is used to provision (bootstrap)  both the server OS-software and the operational stack. Ansible is executed on a local client/desktop system to invoke operations on a remote server/VM. These operations are bundled in so-called Ansible Playbooks, YAML files that describe a desired server state. GitHub Actions are used to construct Workflows. These Actions will invoke these Ansible Playbooks, effectively configuring and provisioning the operational stack on a remote server/VM. </p> <p>Security is guaranteed by the use of Ansible-Vault  and GitHub Encrypted Secrets.</p> <p>Traefik manages the routing of remote requests to relevant containers. Traefik listens to Docker Engine to be aware of available containers. Containers include a dedicated configuration which is picked up by traefik to enable the route. </p>"},{"location":"setup/platform/#services","title":"Services","text":"<p>A number of services has been deployed within the platform, which can act as a template to add additional services. The image below shows the operational service stack with the Traefik frontend.</p> <p></p> <ul> <li>pygeoapi - a Python server implementation of the OGC API suite of standards.</li> <li>pycsw - a Python server implementation of  OGC API Records.</li> <li>GeoServer - a Java server implementation of the OGC API suite of standards.</li> <li>ldproxy - a Java server implementation of the OGC API suite of standards.</li> <li>QGIS Server - server component of QGIS with OGC OAFeat support.</li> <li>GOAF - OAF service developed in Go, maintained by PDOK.</li> <li>PostgreSQL/PostGIS - geospatial database</li> </ul> <p>For administration, documentation and monitoring the following components are used:</p> <ul> <li>mkdocs for live documentation and landing pages</li> <li>PGAdmin - visual PostgreSQL manager  </li> <li>GeoHealthCheck to monitor the availability, compliance and QoS of OGC web services</li> <li>Portainer visual Docker monitor and manager</li> </ul>"},{"location":"setup/platform/#production-and-sandbox-instance","title":"Production and Sandbox Instance","text":"<p>Two separate server/CM-instances are managed to provide stable/production and  sandbox/playground environments. As to control changes these instances are mapped to two GitHub repositories:</p> <ul> <li>https://github.com/Geonovum/ogc-api-testbed for the stable/production instance, nicknamed Stable</li> <li>https://github.com/Geonovum/ogc-api-sandbox the playground instance, nicknamed Sandbox</li> </ul> <p>The Stable repo is a so called GitHub Template repo  from which the Sandbox is cloned.</p> <p>NB initally GitHub Protected Branches were considered, but it felt that those would be less transparent and even confusing for selective access and chances of mistakes.</p>"},{"location":"setup/platform/#other-instances","title":"Other Instances","text":"<p>When other instances are known they are added here. </p>"},{"location":"setup/platform/#ec-jrc","title":"EC JRC","text":"<p>The European Commission Joint Research Centre (EC JRC, Ispra It.) has also used the  Template GitHub repo to create a server instance with OGC Data APIs:  see their landing page at jrc.map5.nl and the GitHub repo at: https://github.com/justb4/ogc-api-jrc .</p>"},{"location":"setup/platform/#selective-redeploy","title":"Selective Redeploy","text":"<p>When changes are pushed to the repo, only the affected services are redeployed. This is effected by a combination of GitHub Actions and Ansible Playbooks as follows:</p> <ul> <li>each Service has a dedicated GitHub Action \"deploy\" file, e.g. deploy.pygeoapi.yml</li> <li>the GitHub Action \"deploy\" file contains a trigger for a <code>push</code> with a <code>paths</code> constraint, in this example:</li> </ul> <pre><code>    on:\n      push:\n        paths:\n          - 'services/pygeoapi/**'\n</code></pre> <ul> <li>the GH Action then calls the Ansible Playbook deploy.yml with a <code>--tags</code> option related to the Service, e.g. <code>--tags pygeoapi</code></li> <li>the deploy.yml will always update the GH repo on the server VM via the <code>pre_tasks</code></li> <li>the Ansible task indicated by the <code>tags</code> is then executed</li> </ul>"},{"location":"setup/platform/#security","title":"Security","text":"<p>Maintaining a public repository and providing secured access to services can be a challenge. Complex solutions exist in the Docker space using Docker Secrets, <code>/etcd</code> service etc We tried to keep it simpler, using Ansible Vault  and GitHub Secrets are the two main mechanisms used for bootstrap and deploy.</p> <p>The bootstrap.yml also applies various Linux hardening components like IP-blacklisting on multiple login attempt, key-only logine etc.</p>"},{"location":"setup/platform/#steps-and-workflows","title":"Steps and Workflows","text":"<p>Below is a shortened version how  to setup and maintain a testbed server instance from zero. In a dedicated HOWTO  all steps are expanded/described in very great detail.</p>"},{"location":"setup/platform/#prerequisites","title":"Prerequisites","text":"<p>This is what you need to have available first.</p>"},{"location":"setup/platform/#access-to-a-servervm","title":"Access to a server/VM","text":"<p>This implies acquiring a server/VM instance from a hosting provider. Main requirements are that server/VM runs an LTS Ubuntu (20.4 or better) and that SSL-keys are available for root access  (or an admin user account with sudo-rights).</p>"},{"location":"setup/platform/#python-3-and-ansible","title":"Python 3 and Ansible","text":"<p>You need a Python 3 installation and install Ansible and <code>git</code> (client).</p>"},{"location":"setup/platform/#clone-template-repo","title":"Clone template repo","text":"<p>Clone from the template repo: https://github.com/Geonovum/ogc-api-testbed.git. See how to do this.</p>"},{"location":"setup/platform/#setup-ansible","title":"Setup Ansible","text":"<p>Adapt the files under <code>git/ansible/vars</code>, following the README there.</p> <p>Adapt the inventory file under <code>git/ansible/hosts</code>, following the README there.</p>"},{"location":"setup/platform/#bootstrap-the-servervm","title":"Bootstrap the server/VM","text":"<p>\"Bootstrap\" here implies the complete provisioning of a remote server/VM that runs the operational service stack. This is a one-time manual action, but can be executed at any time as Ansible actions are idempotent. By its nature, Ansible tasks will only change the system if there is something to do.</p> <p>Startpoint is a fresh Ubuntu-server or VM with root access via SSH-keys (no passwords). The Ansible playbook bootstrap.yml installs the neccessary software, and hardens the server security, e.g. using fail2ban. In this step Docker and Docker Compose are installed and a Linux systemd service is run that automatically starts/stops the operational stack, also on reboots. The software for the operational stack, i.e. from this repo, is cloned on the server as well.</p>"},{"location":"setup/platform/#maintain-the-servervm","title":"Maintain the server/VM","text":"<p>This step is the daily operational maintenance.  The basic substeps are:</p> <ul> <li>make a change, e.g. add a data Collection to an OGC API OAFeat service</li> <li>commit/push the change to GitHub</li> <li>watch the triggered GitHub Actions, check for any errors</li> <li>observe changes via website</li> </ul> <p>As indicated, a dedicated HOWTO describes the above steps in very great detail.</p>"},{"location":"setup/portainer/","title":"Setup portainer","text":"<p>Portainer is a comprehensive webbased tool to monitor running containers in a Docker environment. It connects to Docker enginge to be notified of changes in running containers and hardware usage. From the user interface you can view logs, restart containers, even ssh into a container.</p> <p>Portainer is deployed from https://hub.docker.com/r/portainer/portainer. The portainer data folder is mounted from the host.</p> <p>Portainer is clustered with GeoHealthCheck in a single orchestration.</p> <p>Portainer is available at /portainer/. Do not skip the trailing slash.</p>"},{"location":"setup/postgis/","title":"Setup PostGIS","text":"<p>TO BE SUPPLIED.</p>"},{"location":"setup/pycsw/","title":"pycsw installation experiences/hints","text":"<p>pycsw is a python implementation of Catalogue Service for the Web as well as OGC API Records.</p>"},{"location":"setup/pycsw/#installation","title":"Installation","text":"<p>A docker hub image is provided by geopython. The data folder and the main config file are mounted into the container.</p> <p>The data folder contains a datafile, alternatively you can upload data to a PostGreSQL database.</p> <p>The configuration file has main details such as contact information. Check the documentation to know which properties are supported.</p> <p>Installation on the platform has some challenges because we install the software in a subpath. You can mimic running as root via:</p> <ul> <li>set a stripprefix directive in compose.yml \"traefik.http.middlewares.portainer-stripprefix.stripprefix.prefixes=/pycsw\"</li> <li>tell pycsw to use /pycsw/py.csw as scriptname</li> </ul> <p>Note that /pycsw throws a 500 error for now, but /pycsw/csw.py works fine</p>"},{"location":"setup/pygeoapi/","title":"pygeoapi installation experiences/hints","text":"<p>pygeoapi is a python implementation of the OGC API Suite of standards.</p>"},{"location":"setup/pygeoapi/#installation","title":"Installation","text":"<p>A docker hub image is provided by geopython.  The data folder and the main config file are mounted into the container.</p> <p>The data folder contains the datafiles, alternatively you can upload data to the PostGreSQL database and configure a layer on data from the database.</p> <p>The configuration file contains references to the collections which are exposed via the OGC API's.  Check the documentation to know which backends are supported.</p> <p>You need to set up an instance of pygeoapi for each series of collections you want to serve on an endpoint.</p>"},{"location":"setup/pygeoapi/#brt-background-tiles","title":"BRT background tiles","text":"<p>To find out if BRT background tiles hosted by PDOK can be used, we configured this service to have a map background of WMTS tiles hosted by PDOK. BRT is hosted in epsg:28992 and epsg:3857, the latter is a requirement. Configuration is set up as:</p> <pre><code>    map:\n        url: https://service.pdok.nl/brt/achtergrondkaart/wmts/v2_0/standaard/EPSG:3857/{z}/{x}/{y}.png\n        attribution: 'Map data &amp;copy; &lt;a href=\"https://pdok.nl\"&gt;PDOK Kadaster&lt;/a&gt;'\n</code></pre>"},{"location":"setup/pygeoapi/#inspire","title":"INSPIRE","text":"<p>We used this installation of pygeoapi to research the INSPIRE use case. Adding several types of links as suggested by INSPIRE is doable in pygeoapi. The software doesn't help much, but also doesn't limit you in the type of links you want to add, our configuration is:</p> <pre><code>        links:\n            - type: text/html\n              rel: describedby\n              title: Metadata as HTML\n              href: https://www.nationaalgeoregister.nl/geonetwork/srv/metadata/45eaae76-874a-4fe1-88f4-820517e3de73\n              hreflang: nl\n            - type: application/xml\n              rel: describedby\n              title: Metadata as iso19139 xml\n              href: https://www.nationaalgeoregister.nl/geonetwork/srv/metadata/45eaae76-874a-4fe1-88f4-820517e3de73/formatters/xml\n              hreflang: nl\n            - type: text/html\n              rel: tag\n              title: Referentie naar het concept beschermde gebieden (inspire registry)\n              href: http://inspire.ec.europa.eu/featureconcept/ProtectedSite\n              hreflang: nl\n            - type: application/gml+xml\n              rel: enclosure\n              title: Download volledige dataset Werelderfgoed als GML\n              href: https://service.pdok.nl/rce/ps-ch/wfs/v1_0?request=GetFeature&amp;service=WFS&amp;version=1.1.0&amp;typeName=ps-ch:rce_inspire_polygons&amp;outputFormat=text%2Fxml%3B%20subtype%3Dgml%2F3.1.1\n              hreflang: nl\n</code></pre>"},{"location":"setup/qgis/","title":"Setup QGIS Server","text":"<p>qgis is a desktop as well as a server solution. The server solution provides typical OGC services sucha as WMS, WFS. Since recently also OGC API Features is available. </p> <p>Deployed docker image from https://hub.docker.com/r/camptocamp/qgis-server. Following the hints from https://www.qcooperative.net/blog/ogcapif/ and https://docs.qgis.org/testing/en/docs/server_manual/services.html#wfs3-ogc-api-features</p>"},{"location":"setup/qgis/#issues","title":"Issues","text":"<p>I had a hard time finding in documentation what the  url is to open ogc api features endpoint,  it appears to be '/qgis/wfs3'.  I assume this will likely be changed in upcoming versions.</p> <p>Somehow the feature collections are not loaded,  although the WMS is able to display them</p>"},{"location":"setup/qgis/#container-write-permission","title":"Container Write Permission","text":"<p>Could not use the default <code>/etc/qgisserver/project.qgs</code> Docker volume mapping, as the referenced GPKG files needed write access (for WAL files) in that dir. The solutions was to set <code>QGIS_PROJECT_FILE</code> explicitly. However it resulted in a working situation, but the project file could not be located by the service. So I restored the situation. It means we still have no write privileges in the data folder.</p> <pre><code>    environment:\n      # Must override default to allow write access e.g. GPKG WALs for www-data user\n      - QGIS_PROJECT_FILE:/myqgisserver/project.qgs\n\n      #- QGIS_SERVER_LOG_LEVEL:0\n      #- PGSERVICEFILE:If you want to change the default of /etc/qgisserver/pg_service.conf\n      #- QGIS_PROJECT_FILE:If you want to change the default of /etc/qgisserver/project.qgs\n      #- MAX_REQUESTS_PER_PROCESS:The number of requests a QGIS server will serve before being restarted by apache\n      #- QGIS_CATCH_SEGV:1\n\n    volumes:\n      # Map data and config into container\n      - ./data:/myqgisserver\n</code></pre>"},{"location":"setup/qgis/#publish-layers-as-wfs-on-the-project","title":"Publish layers as WFS on the project","text":"<p>I ran into the problem that the layers were displayed on the WMS capabilities, but not as collections on ogc api features. I requested help from the qgis mailinglist, but no direct solution. Until Allesandro Pasotti pointed me on the fact that I have to activate WFS on layers before they are available via WFS and OGC API Features. You can set WFS access via project properties &gt; QGIS Server &gt; WFS.</p>"}]}